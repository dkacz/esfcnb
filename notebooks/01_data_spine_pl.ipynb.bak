{"cells": [{"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --- Project root bootstrap for imports (works in VS Code, WSL, headless) ---\n", "import sys, importlib.util\n", "from pathlib import Path\n", "\n", "def find_repo_root() -> Path:\n", "    \"\"\"\n", "    Walk up from CWD to locate the project root by markers:\n", "    scripts/sfc_pl_runner.py and config/sfc_pl_runner.yml.\n", "    \"\"\"\n", "    here = Path.cwd().resolve()\n", "    for parent in (here, *here.parents):\n", "        if (parent / 'scripts' / 'sfc_pl_runner.py').exists() and (parent / 'config' / 'sfc_pl_runner.yml').exists():\n", "            return parent\n", "    raise FileNotFoundError('Could not find project root with scripts/sfc_pl_runner.py and config/sfc_pl_runner.yml')\n", "\n", "ROOT = find_repo_root()\n", "if str(ROOT) not in sys.path:\n", "    sys.path.insert(0, str(ROOT))\n", "print('Project root:', ROOT)\n", "\n", "# Primary import (package import requires scripts/__init__.py)\n", "try:\n", "    from scripts.sfc_pl_runner import load_config, run_from_config, verify\n", "    print('Imported from package:', ROOT / 'scripts' / 'sfc_pl_runner.py')\n", "except ModuleNotFoundError:\n", "    # Absolute path fallback (rarely needed if sys.path is set and scripts/__init__.py exists)\n", "    mfp = ROOT / 'scripts' / 'sfc_pl_runner.py'\n", "    spec = importlib.util.spec_from_file_location('scripts.sfc_pl_runner', str(mfp))\n", "    mod = importlib.util.module_from_spec(spec)\n", "    spec.loader.exec_module(mod)  # type: ignore[attr-defined]\n", "    load_config, run_from_config, verify = mod.load_config, mod.run_from_config, mod.verify\n", "    print('Imported via file path:', mfp)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["CFG = load_config()\n", "rc = verify(CFG)\n", "print('verify() exit code:', rc)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Data Spine \u2014 Poland (Eurostat + ECB)\n", "\n", "This notebook orchestrates Step 1 pulls and QC via the fixed runner."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### VERIFY & FIX (STEP 1.2)\n", "\n", "Run All to pull SDMX data and print the verification block."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# (Optional) full pipeline from notebook (skipped by default)\n", "import os\n", "if os.environ.get('NOTEBOOK_PULL')=='1':\n", "    _ = run_from_config(CFG)\n", "else:\n", "    print('Skipping full pull (set NOTEBOOK_PULL=1 to enable)')\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Single-source verification print (JSON-driven)\n# Always call verify() at least once so it writes the snapshot JSON and exit code.\nrc = verify(CFG)\nprint(f\"verify() exit code: {rc}\")\n\n# The rest of the display must be built from the freshly written JSON.\nimport json, pandas as pd\nfrom pathlib import Path\nvr = json.loads((ROOT / 'data' / 'processed' / 'verification_report.json').read_text(encoding='utf-8'))\n\n# --- Artifacts table ---\nart_rows = []\nfor p, meta in vr.get('artifacts', {}).items():\n    art_rows.append({\n        'path': p,\n        'exists': meta.get('exists'),\n        'size_bytes': meta.get('size_bytes'),\n        'rows': meta.get('rows'),\n        'cols': meta.get('cols'),\n        'first_quarter': meta.get('first_quarter'),\n        'last_quarter': meta.get('last_quarter'),\n    })\nart_df = pd.DataFrame(art_rows).sort_values('path')\ndisplay(art_df)\n\n# Echo NF_TR scope, QC, anchors, failures from JSON\ndisplay(vr.get('nf_tr_scope', {}))\ndisplay(vr.get('qc_summary', {}))\ndisplay(vr.get('anchors', {}))\ndisplay(vr.get('failures', {}))\n\n# Checksums (file & sample) from JSON\ndisplay(vr.get('checksums', {}))\n\n# Hard stop on failure (notebook)\nVERIFY_RC = rc\n# soft-fail: do not abort; proof cell will still run\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Re-run verification only (idempotent); prints full block\n", "from scripts.sfc_pl_runner import verify\n", "rc = verify(CFG)\nprint('verify() returned:', rc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Output Gate & Debug Pack \u2014 Self-contained\n", "Run to print the artifacts table, schema checks, NF_TR scope, QC summary, anchors, and failure lines."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Print the full verification block (includes artifacts, schema, scope, QC, anchors, failures)\n", "from scripts.sfc_pl_runner import verify\n", "rc = verify(CFG)\nprint('verify() returned:', rc)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Convenience: print single worst stocks-bridge line + one failure log line if any\n", "import json, re, pathlib\n", "qc=json.load(open('data/processed/qc_summary.json')) if pathlib.Path('data/processed/qc_summary.json').exists() else {}\n", "worst=(qc.get('stocks_bridge',{}).get('worst10') or [])\n", "print('WORST stocks-bridge line:', worst[0] if worst else None)\n", "# Show first fetch failure logged\n", "log_lines=[]\n", "try:\n", "    with open('logs/sfc_pl_runner.log','r',encoding='utf-8') as fh:\n", "        for ln in fh:\n", "            if ln.strip().startswith('FAIL | dataset='):\n", "                log_lines.append(ln.strip())\n", "except FileNotFoundError:\n", "    pass\n", "print('ONE failure line (if any):', log_lines[0] if log_lines else None)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --- Notebook run proof: emit a runtime token and bind it to the JSON snapshot ---\nimport os, sys, json, time, hashlib, platform\nfrom pathlib import Path\n\nvr_path = (ROOT / 'data' / 'processed' / 'verification_report.json')\nassert vr_path.exists(), \"verification_report.json not found; run verify(CFG) first\"\nvr_bytes = vr_path.read_bytes()\nvr_sha = hashlib.sha256(vr_bytes).hexdigest()\n\n# Runtime-only token (cannot exist without execution)\nnonce = os.urandom(32)\nnow_ns = time.time_ns()\nproof_token = hashlib.sha256(nonce + str(now_ns).encode('utf-8')).hexdigest()[:16]\n\nproof = {\n    \"run_utc\": time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),\n    \"cwd\": str(Path.cwd().resolve()),\n    \"python\": sys.version,\n    \"platform\": platform.platform(),\n    \"verification_report_sha256\": vr_sha,\n    \"proof_token\": proof_token,\n}\n\nproof_path = ROOT / 'data' / 'processed' / '_nb_run_proof.json'\nproof_path.parent.mkdir(parents=True, exist_ok=True)\nproof_path.write_text(json.dumps(proof, indent=2), encoding='utf-8')\nprint('NOTEBOOK_RUN_PROOF', proof_token, vr_sha)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}